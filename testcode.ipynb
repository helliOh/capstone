{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy 1.0.1\n",
      "numpy 1.14.2\n",
      "matplotlib 2.2.2\n",
      "pandas 0.22.0\n",
      "sklearn 0.19.1\n",
      "h5py 2.7.1\n",
      "tensorflow 1.2.1\n",
      "keras 2.1.5\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy\n",
    "import matplotlib\n",
    "import pandas\n",
    "import sklearn\n",
    "import pydotplus\n",
    "import h5py\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "\n",
    "print('scipy ' + scipy.__version__ );\n",
    "print('numpy ' + numpy.__version__ );\n",
    "print('matplotlib ' + matplotlib.__version__ );\n",
    "print('pandas ' + pandas.__version__ );\n",
    "print('sklearn ' + sklearn.__version__ );\n",
    "print('h5py ' + h5py.__version__ );\n",
    "\n",
    "print('tensorflow ' + tensorflow.__version__ );\n",
    "print('keras ' + keras.__version__ );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.6869 - acc: 0.8249\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3505 - acc: 0.9013\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3028 - acc: 0.9142\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2743 - acc: 0.9220\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2525 - acc: 0.9287\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "loss_and_metrics : [0.23972345739603043, 0.93149999999999999]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=5, batch_size=32)\n",
    "\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 313.00 221.00\" width=\"313pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-217 309,-217 309,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 189915432 -->\n",
       "<g class=\"node\" id=\"node1\"><title>189915432</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 305,-212.5 305,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-185.8\">dense_1_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"166,-166.5 166,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"166,-189.5 222,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-166.5 222,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-197.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"222,-189.5 305,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263.5\" y=\"-174.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 84455944 -->\n",
       "<g class=\"node\" id=\"node2\"><title>84455944</title>\n",
       "<polygon fill=\"none\" points=\"31,-83.5 31,-129.5 274,-129.5 274,-83.5 31,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83\" y=\"-102.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"135,-83.5 135,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"135,-106.5 191,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191,-83.5 191,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-114.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"191,-106.5 274,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-91.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 189915432&#45;&gt;84455944 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>189915432-&gt;84455944</title>\n",
       "<path d=\"M152.5,-166.366C152.5,-158.152 152.5,-148.658 152.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156,-139.607 152.5,-129.607 149,-139.607 156,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 84456112 -->\n",
       "<g class=\"node\" id=\"node3\"><title>84456112</title>\n",
       "<polygon fill=\"none\" points=\"34,-0.5 34,-46.5 271,-46.5 271,-0.5 34,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86\" y=\"-19.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"138,-0.5 138,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"138,-23.5 194,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"194,-0.5 194,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-31.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"194,-23.5 271,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-8.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 84455944&#45;&gt;84456112 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>84455944-&gt;84456112</title>\n",
       "<path d=\"M152.5,-83.3664C152.5,-75.1516 152.5,-65.6579 152.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"156,-56.6068 152.5,-46.6068 149,-56.6069 156,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model,  show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('mnist_mlp_model.h5')\n",
    "model = load_model('mnist_mlp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bf8d1e034e32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         validation_steps=5)\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'resrc/test/handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'resrc/test/handwriting_shape/test',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(24,24,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15,\n",
    "        epochs=50,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)\n",
    "\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "data_aug_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=10,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.7,\n",
    "                                 zoom_range=[0.9, 2.2],\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True,\n",
    "                                 fill_mode='nearest')\n",
    "\n",
    "img = load_img('resrc/test/handwriting_shape/train/triangle/triangle001.png')\n",
    "x = img_to_array(img)\n",
    "\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for batch in data_aug_gen.flow(x, batch_size=1, save_to_dir='resrc/test/preview/triangles', save_prefix='tri', save_format='png') : \n",
    "    i +=  1\n",
    "    if i > 50 :\n",
    "        print('generated done!')\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.2001 - acc: 0.9153 - val_loss: 2.3842e-06 - val_acc: 1.0000\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0388 - acc: 0.9856 - val_loss: 1.5037e-05 - val_acc: 1.0000\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0314 - acc: 0.9891 - val_loss: 1.9083e-05 - val_acc: 1.0000\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0257 - acc: 0.9920 - val_loss: 2.4558e-06 - val_acc: 1.0000\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0203 - acc: 0.9931 - val_loss: 2.0663e-07 - val_acc: 1.0000\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0192 - acc: 0.9938 - val_loss: 1.0133e-06 - val_acc: 1.0000\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0137 - acc: 0.9949 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0144 - acc: 0.9951 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0283 - acc: 0.9931 - val_loss: 1.5895e-07 - val_acc: 1.0000\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0173 - acc: 0.9956 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0234 - acc: 0.9940 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 12/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0115 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 13/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0065 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 14/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0213 - acc: 0.9953 - val_loss: 3.8942e-07 - val_acc: 1.0000\n",
      "Epoch 15/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 16/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0152 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0243 - acc: 0.9947 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 18/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0100 - acc: 0.9976 - val_loss: 1.8279e-07 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "1500/1500 [==============================] - 52s 34ms/step - loss: 0.0332 - acc: 0.9951 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0097 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.0167 - acc: 0.997 - 47s 31ms/step - loss: 0.0167 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0208 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0165 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0127 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0159 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0123 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0100 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0079 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0159 - acc: 0.9982 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0112 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0369 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0105 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0018 - acc: 0.9993 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0269 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0314 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0252 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "1500/1500 [==============================] - 48s 32ms/step - loss: 0.0297 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0090 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0090 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0150 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0086 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0044 - acc: 0.9996 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0172 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "1500/1500 [==============================] - 47s 32ms/step - loss: 1.5068e-04 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0354 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0125 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0296 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0209 - acc: 0.9980 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0144 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "1500/1500 [==============================] - 43s 28ms/step - loss: 0.0058 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0264 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0322 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0271 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0240 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 4.3711e-05 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0326 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0372 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0278 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0080 - acc: 0.9993 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0162 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0156 - acc: 0.9982 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0614 - acc: 0.9951 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0248 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "1500/1500 [==============================] - 48s 32ms/step - loss: 0.0417 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0171 - acc: 0.9982 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0066 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0306 - acc: 0.9980 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0408 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0277 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0181 - acc: 0.9982 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0107 - acc: 0.9993 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0627 - acc: 0.9953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "1500/1500 [==============================] - 44s 29ms/step - loss: 0.0476 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0309 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0339 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0079 - acc: 0.9993 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0298 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0486 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0200 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "1500/1500 [==============================] - 48s 32ms/step - loss: 0.0458 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0190 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0106 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0101 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0436 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0167 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.1410 - acc: 0.9909 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0323 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0322 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0187 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0244 - acc: 0.9980 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0206 - acc: 0.9982 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0517 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0433 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "1500/1500 [==============================] - 47s 32ms/step - loss: 0.0308 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0782 - acc: 0.9947 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0247 - acc: 0.9980 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0498 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0130 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0307 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0469 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0379 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0196 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0327 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0414 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0220 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0197 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0930 - acc: 0.9940 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0803 - acc: 0.9944 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0136 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0324 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0246 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "1500/1500 [==============================] - 45s 30ms/step - loss: 0.0652 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0398 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0272 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "1500/1500 [==============================] - 46s 31ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0861 - acc: 0.9942 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.1718 - acc: 0.9891 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "1500/1500 [==============================] - 46s 30ms/step - loss: 0.0521 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "1500/1500 [==============================] - 44s 29ms/step - loss: 0.0716 - acc: 0.9956 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "1500/1500 [==============================] - 43s 29ms/step - loss: 0.0726 - acc: 0.9949 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "1500/1500 [==============================] - 44s 29ms/step - loss: 0.0337 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "1500/1500 [==============================] - 43s 29ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "1500/1500 [==============================] - 43s 29ms/step - loss: 0.0577 - acc: 0.9962 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "1500/1500 [==============================] - 43s 29ms/step - loss: 0.0472 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "1500/1500 [==============================] - 44s 29ms/step - loss: 0.0509 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "1500/1500 [==============================] - 43s 29ms/step - loss: 0.1118 - acc: 0.9927 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "1500/1500 [==============================] - 43s 28ms/step - loss: 0.0133 - acc: 0.9991 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "1500/1500 [==============================] - 43s 28ms/step - loss: 0.0605 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0708 - acc: 0.9953 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0188 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "1500/1500 [==============================] - 43s 29ms/step - loss: 0.0251 - acc: 0.9982 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0591 - acc: 0.9958 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0178 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.1184 - acc: 0.9924 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0518 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "1500/1500 [==============================] - 44s 29ms/step - loss: 0.0238 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "1500/1500 [==============================] - 43s 28ms/step - loss: 0.0450 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "1500/1500 [==============================] - 43s 28ms/step - loss: 0.0206 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0354 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0314 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0379 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0427 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0641 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0216 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0176 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0336 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0243 - acc: 0.9980 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0684 - acc: 0.9956 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0469 - acc: 0.9969 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0713 - acc: 0.9949 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0394 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0215 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0853 - acc: 0.9942 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0479 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0108 - acc: 0.9993 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0337 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0326 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0982 - acc: 0.9936 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0430 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0502 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0189 - acc: 0.9987 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "1500/1500 [==============================] - 43s 28ms/step - loss: 0.0231 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0358 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0975 - acc: 0.9938 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0251 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0349 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0315 - acc: 0.9978 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "1500/1500 [==============================] - 43s 28ms/step - loss: 0.0369 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0287 - acc: 0.9982 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "1500/1500 [==============================] - 2076s 1s/step - loss: 0.0533 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0342 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0251 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0179 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0251 - acc: 0.9984 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0036 - acc: 0.9998 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0322 - acc: 0.9980 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0449 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.1318 - acc: 0.9918 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0394 - acc: 0.9976 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0969 - acc: 0.9938 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0178 - acc: 0.9989 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0501 - acc: 0.9964 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0466 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0583 - acc: 0.9960 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0712 - acc: 0.9956 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0537 - acc: 0.9967 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0257 - acc: 0.9980 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0459 - acc: 0.9971 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0390 - acc: 0.9973 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "1500/1500 [==============================] - 42s 28ms/step - loss: 0.0877 - acc: 0.9944 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "-- Evaluate --\n",
      "acc: 100.00%\n",
      "-- Predict --\n",
      "[[0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 1.000 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [0.000 0.000 1.000]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(3)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.7,\n",
    "                                   zoom_range=[0.9, 2.2],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'resrc/test/handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'resrc/test/handwriting_shape/test',\n",
    "        target_size=(24, 24),    \n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(24,24,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15 * 100,\n",
    "        epochs=200,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(\n",
    "            test_generator, \n",
    "            steps = 5)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "\n",
    "output = model.predict_generator(\n",
    "            test_generator, \n",
    "            steps = 5)\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "150/150 [==============================] - 5s 35ms/step - loss: 0.8038 - acc: 0.6267 - val_loss: 0.4840 - val_acc: 0.7333\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 5s 31ms/step - loss: 0.3043 - acc: 0.9000 - val_loss: 0.1239 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 5s 32ms/step - loss: 0.1853 - acc: 0.9333 - val_loss: 0.1407 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 5s 32ms/step - loss: 0.1289 - acc: 0.9533 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 5s 31ms/step - loss: 0.1283 - acc: 0.9667 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 5s 31ms/step - loss: 0.0786 - acc: 0.9711 - val_loss: 0.0111 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 5s 32ms/step - loss: 0.0624 - acc: 0.9844 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 5s 31ms/step - loss: 0.0565 - acc: 0.9756 - val_loss: 1.5944e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 5s 31ms/step - loss: 0.0511 - acc: 0.9800 - val_loss: 3.0766e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 5s 32ms/step - loss: 0.0753 - acc: 0.9733 - val_loss: 0.1286 - val_acc: 0.8667\n",
      "-- Evaluate --\n",
      "acc: 86.67%\n",
      "-- Predict --\n",
      "[[0.001 0.999 0.000]\n",
      " [0.001 0.999 0.000]\n",
      " [0.001 0.999 0.000]\n",
      " [0.000 0.000 1.000]\n",
      " [1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.579 0.000 0.421]\n",
      " [0.000 1.000 0.000]\n",
      " [1.000 0.000 0.000]\n",
      " [0.002 0.000 0.998]\n",
      " [0.000 1.000 0.000]\n",
      " [0.652 0.000 0.347]\n",
      " [0.000 0.000 1.000]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(3)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.7,\n",
    "                                   zoom_range=[0.9, 2.2],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'resrc/test/handwriting_shape/train',\n",
    "        target_size=(24, 24),\n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'resrc/test/handwriting_shape/test',\n",
    "        target_size=(24, 24),    \n",
    "        batch_size=3,\n",
    "        class_mode='categorical')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(24,24,3)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=15 * 10,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)\n",
    "\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(\n",
    "            test_generator, \n",
    "            steps = 5)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "\n",
    "output = model.predict_generator(\n",
    "            test_generator, \n",
    "            steps = 5)\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
