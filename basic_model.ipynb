{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "\n",
    "base_path =  './resrc/test/sets/'\n",
    "data_filter_type = ['no_filter', 'edges', 'threshold']#no_filter, edges, threshold\n",
    "_path = base_path + data_filter_type[0]\n",
    "\n",
    "train_path = _path + '/train'\n",
    "test_path = _path + '/test'\n",
    "\n",
    "print('train p : ' + train_path)\n",
    "print('test p : ' + test_path)\n",
    "\n",
    "train_data_size = len(listdir(train_path))\n",
    "test_data_size = len(listdir(test_path))\n",
    "\n",
    "print('train num : ', train_data_size)\n",
    "print('test num : ', test_data_size)\n",
    "\n",
    "# data set ------------------------------------------------------\n",
    "np.random.seed(3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(1)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size = (240, 240),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(1)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size = (240, 240),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "# model ------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(24, 24), # output = (240 * 240) * 3 * 32 / kernel_size * channel * kernel_num\n",
    "                 padding='same',\n",
    "                 input_shape=(240,240,3),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(24, 24), # output = (240 * 240) * 3 * 100\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))# output = (120 * 120) * 100  = 1440000\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model  compile ------------------------------------------------------\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model training ------------------------------------------------------\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator)\n",
    "\n",
    "# model evaluating ------------------------------------------------------\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(test_generator)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "\n",
    "base_path =  './resrc/test/sets/'\n",
    "data_filter_type = ['no_filter', 'edges', 'threshold']#no_filter, edges, threshold\n",
    "_path = base_path + data_filter_type[1]\n",
    "\n",
    "train_path = _path + '/train'\n",
    "test_path = _path + '/test'\n",
    "\n",
    "print('train p : ' + train_path)\n",
    "print('test p : ' + test_path)\n",
    "\n",
    "train_data_size = len(listdir(train_path))\n",
    "test_data_size = len(listdir(test_path))\n",
    "\n",
    "print('train num : ', train_data_size)\n",
    "print('test num : ', test_data_size)\n",
    "\n",
    "# data set ------------------------------------------------------\n",
    "np.random.seed(3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(1)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size = (240, 240),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(1)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size = (240, 240),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "# model ------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(24, 24), # output = (240 * 240) * 3 * 32 / kernel_size * channel * kernel_num\n",
    "                 padding='same',\n",
    "                 input_shape=(240,240,3),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(24, 24), # output = (240 * 240) * 3 * 100\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))# output = (120 * 120) * 100  = 1440000\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model  compile ------------------------------------------------------\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model training ------------------------------------------------------\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator)\n",
    "\n",
    "# model evaluating ------------------------------------------------------\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(test_generator)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "\n",
    "base_path =  './resrc/test/sets/'\n",
    "data_filter_type = ['no_filter', 'edges', 'threshold']#no_filter, edges, threshold\n",
    "_path = base_path + data_filter_type[2]\n",
    "\n",
    "train_path = _path + '/train'\n",
    "test_path = _path + '/test'\n",
    "\n",
    "print('train p : ' + train_path)\n",
    "print('test p : ' + test_path)\n",
    "\n",
    "train_data_size = len(listdir(train_path))\n",
    "test_data_size = len(listdir(test_path))\n",
    "\n",
    "print('train num : ', train_data_size)\n",
    "print('test num : ', test_data_size)\n",
    "\n",
    "# data set ------------------------------------------------------\n",
    "np.random.seed(3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(1)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size = (240, 240),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(1)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size = (240, 240),\n",
    "        batch_size = 32,\n",
    "        class_mode = 'binary')\n",
    "\n",
    "# model ------------------------------------------------------\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(24, 24), # output = (240 * 240) * 3 * 32 / kernel_size * channel * kernel_num\n",
    "                 padding='same',\n",
    "                 input_shape=(240,240,3),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(24, 24), # output = (240 * 240) * 3 * 100\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))# output = (120 * 120) * 100  = 1440000\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model  compile ------------------------------------------------------\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model training ------------------------------------------------------\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=test_generator)\n",
    "\n",
    "# model evaluating ------------------------------------------------------\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(test_generator)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
